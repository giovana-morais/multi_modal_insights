{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAqxPbq1nQqz"
      },
      "source": [
        "# Init\n",
        "Requires GPU to use quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_AHsJsbknQq1"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U transformers==4.37.2\n",
        "!pip install -q bitsandbytes==0.41.3 accelerate==0.25.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OKU7yPQnQq3",
        "outputId": "40ad0d65-d9ef-4723-f850-d36158495219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Video to Frames"
      ],
      "metadata": {
        "id": "AWUPIF0EsGcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "9ffxiqzNzkW7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disk version. Saves frames to a folder for human examination/clustering, etc. We can open the images later, if necessary."
      ],
      "metadata": {
        "id": "rOz0W5vkFmjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "\n",
        "video_path = \"/under_water.mp4\"\n",
        "output_path = \"/media\" #ATTENTION! The contents of this folder will be removed before each run.\n",
        "\n",
        "def addzeros(i, length):\n",
        "  ans = str(i)\n",
        "  while(len(ans)<len(str(length))):\n",
        "    ans = \"0\"+ ans\n",
        "  return ans\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "files = glob.glob(output_path+\"/*\")\n",
        "for f in files:\n",
        "    os.remove(f)\n",
        "\n",
        "num_frames = 6 #desired number of frames\n",
        "\n",
        "vid_obj = cv2.VideoCapture(video_path)\n",
        "\n",
        "length = int(vid_obj.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(length)\n",
        "\n",
        "frames = []\n",
        "\n",
        "i = 0\n",
        "result = True\n",
        "\n",
        "while(i<length):\n",
        "    vid_obj.set(cv2.CAP_PROP_POS_FRAMES,i)\n",
        "    result, image = vid_obj.read()\n",
        "    frames.append(image)\n",
        "    output_fullpath = output_path + \"/frame\" + addzeros(i,length) + \".jpg\"\n",
        "    cv2.imwrite(output_fullpath,image)\n",
        "    i+=math.ceil(length/num_frames)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd95Bn7psOtw",
        "outputId": "53423386-6b3f-4f05-ead1-fb15f8aee655"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAM version. A slightly faster version for direct evaluation with BLIP. No files are stored."
      ],
      "metadata": {
        "id": "kwcnePZJsOX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "\n",
        "video_path = \"/under_water.mp4\"\n",
        "\n",
        "num_frames = 6 #desired number of frames\n",
        "\n",
        "vid_obj = cv2.VideoCapture(video_path)\n",
        "\n",
        "length = int(vid_obj.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(length)\n",
        "\n",
        "frames = []\n",
        "\n",
        "i = 0\n",
        "result = True\n",
        "\n",
        "while(i<length):\n",
        "    vid_obj.set(cv2.CAP_PROP_POS_FRAMES,i)\n",
        "    result, image = vid_obj.read()\n",
        "    frames.append(image)\n",
        "    i+=math.ceil(length/num_frames)"
      ],
      "metadata": {
        "id": "cmUXT6KTsOEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bf55df-1dc1-43a2-bda6-fe74f84bf491"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ11CXn3nQq4"
      },
      "source": [
        "# Blip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "# list to store files\n",
        "res = []\n",
        "\n",
        "descriptions = []\n",
        "for raw_image in frames:\n",
        "    inputs = processor(raw_image, return_tensors=\"pt\")\n",
        "\n",
        "    out = model.generate(**inputs)\n",
        "    descriptions.append(processor.decode(out[0], skip_special_tokens=True))\n",
        "\n",
        "print(descriptions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVFdmzvJCgWl",
        "outputId": "9ee19f57-7533-4b22-d804-7831ba1c8e09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a fish tank with a fish inside of it', 'a boat in a tank with fish swimming around', 'a large fish swimming in a tank filled with water', 'a large group of fish swimming in an aquarium', 'a large group of fish swimming in a tank', 'a large group of fish swimming in a tank']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WEh7mbNrHA3D"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}