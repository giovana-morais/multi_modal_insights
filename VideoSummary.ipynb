{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
      "     ------------------------------------- 798.6/798.6 kB 12.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-win_amd64.whl (798 kB)\n",
      "     ------------------------------------- 798.7/798.7 kB 25.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.0/57.0 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from openai-whisper) (4.66.2)\n",
      "Requirement already satisfied: torch in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from openai-whisper) (2.2.2)\n",
      "Collecting numba\n",
      "  Downloading numba-0.59.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 34.1 MB/s eta 0:00:00\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0\n",
      "  Using cached llvmlite-0.42.0-cp310-cp310-win_amd64.whl (28.1 MB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from torch->openai-whisper) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from torch->openai-whisper) (4.11.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from torch->openai-whisper) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from torch->openai-whisper) (3.1.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\felip\\documents\\github\\autodescription\\venv\\lib\\site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801375 sha256=08b15f9c177422e705bf2448f597f67458b5408b9cb718662539e33ccb2f2e12\n",
      "  Stored in directory: c:\\users\\felip\\appdata\\local\\pip\\cache\\wheels\\d0\\85\\e1\\9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: more-itertools, llvmlite, tiktoken, numba, openai-whisper\n",
      "Successfully installed llvmlite-0.42.0 more-itertools-10.2.0 numba-0.59.1 openai-whisper-20231117 tiktoken-0.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper\n",
    "!pip install pytube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pytube import YouTube\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "summarizer = pipeline(\"summarization\",model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def get_audio(url):\n",
    "  yt = YouTube(url)\n",
    "  video = yt.streams.filter(only_audio=True).first()\n",
    "  out_file=video.download(output_path=\".\")\n",
    "  base, ext = os.path.splitext(out_file)\n",
    "  new_file = './files/audio.mp3'\n",
    "  os.rename(out_file, \"./files/audio.mp3\")\n",
    "  a = new_file\n",
    "  return a\n",
    "\n",
    "def get_text(url):\n",
    "  result = model.transcribe(get_audio(url))\n",
    "  return result['text']\n",
    "\n",
    "def get_summary(url):\n",
    "  article = get_text(url)\n",
    "  b = summarizer(article)\n",
    "  b = b[0]['summary_text']\n",
    "  return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = get_audio(\"https://www.youtube.com/watch?v=26PrgjTboVQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\felip\\Documents\\Github\\AutoDescription\\venv\\lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "transcript = model.transcribe(\"./files/audio.mp3\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6 Minute English from BBCLearningEnglish.com Hello, this is 6 Minute English from BBCLearningEnglis\n"
     ]
    }
   ],
   "source": [
    "print(transcript[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarizer(transcript[0:1023])[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Minute English: Follow your childhood dreams. Hear how Daisy and Herman made their dreams come true. And as usual, we'll be learning some new vocabulary. But before that, I have a question for you, Beth. Did you have any childhood dreams? I wanted to be an astronaut and fly to the moon.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
